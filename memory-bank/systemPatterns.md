# System Patterns: MCP-Agent

## 1. Architectural Overview

A modular architecture will be implemented in Python.

```mermaid
graph TD
    A[User Input Interface (CLI)] --> B(Input Parser);
    B -- Cleaned Text --> C(Use Case Generator / LLM Interaction);
    C -- Structured Use Cases --> D(MCP/API Search Engine);
    D -- Use Cases + Found APIs & Details --> E(Results Formatter);
    E -- Formatted Report (Markdown) --> F[Output Display (Console)];

    subgraph Core Logic Modules (Python)
        B[src/input_parser.py]
        C[src/use_case_generator.py]
        D[src/search_engine/]
        E[src/results_formatter.py]
    end

    C --> X[LLM API (External for UseCaseGenerator)];
    C --> Y[Prompt Templates (Managed within Use Case Generator)];
    D --> Z_GH_LLM[LLM API (External for GitHubSource)];
    D --> Z_GH_API[GitHub API (for READMEs/Stars)];
    D --> Z_GH_CACHE[Curated GitHub READMEs (Local Cache)];
    Z_GH_CACHE --> D;
    F --> G[User's Terminal]
```

- **User Input Interface (CLI):** Initially, a command-line interface where the user provides product requirements as text. Handled by `src/main.py` or `src/cli.py`.
- **Input Parser (`src/input_parser.py`):**
  - Receives raw text input.
  - Performs cleaning (whitespace, basic normalization).
  - Potentially segments text if too long for LLM context windows.
- **Use Case Generator / LLM Interaction (`src/use_case_generator.py`):**
  - Constructs a prompt using pre-defined templates and the cleaned requirements.
  - Sends the prompt to an external LLM API (e.g., OpenAI, Anthropic).
  - Receives and parses the LLM's response to extract structured use cases (e.g., list of strings or simple objects).
  - Manages LLM API key via `src/config.py`.
- **MCP/API Search Engine (`src/search_engine/` package):**
  - Takes structured use cases one by one.
  - For each use case, formulates search queries.
  - Iterates through a configured, prioritized list of sources:
    - Specific MCP/API websites (e.g., `mcp.pipedream.com`, `mcpmarket.com`) (implementation deferred for these specific sources).
    - `GitHubSource` (`src/search_engine/sources/github_source.py`):
      - Maintains local cached copies of predefined GitHub README files (e.g., from `modelcontextprotocol/servers`, `punkpeye/awesome-mcp-servers`, `appcypher/awesome-mcp-servers`) located in `resources/github/`.
      - Updates these caches periodically if a `GITHUB_TOKEN` is available and files are older than one week.
      - Uses an LLM (e.g., `gpt-4.1-mini`) with a detailed system prompt to analyze the content of these cached files against the user's use case.
      - Extracts relevant sections from the Markdown (using `markdown-it-py`) for focused LLM analysis.
      - Optionally fetches GitHub stars for identified MCPs using the GitHub API.
    - General API directories or search engines as fallback if needed (implementation deferred).
  - Extracts MCP/API names, descriptions, links, and relevant metadata.
  - Implemented with sub-modules for each source type.
- **Results Formatter (`src/results_formatter.py`):**
  - Takes the list of use cases and their corresponding top N found MCPs/APIs.
  - Organizes this data into a human-readable Markdown report.
- **Output Display (Console):**
  - The main script (`src/main.py`) will print the Markdown report generated by the Results Formatter to the standard output (user's terminal).

## 2. Key Technical Decisions & Patterns

- **Language:** Python.
- **Modularity:** Each component above will be a distinct Python module or package.
- **Configuration:** API keys, source URLs, and other configurations managed by `src/config.py` using `python-dotenv` and an `.env` file.
- **Asynchronous Operations:** `httpx` and `asyncio` will be used for concurrent network requests in the MCP/API Search Engine to improve performance.
- **Error Handling:** Standard Python `try-except` blocks within modules, with logging (`logging` module). Critical errors propagated to `main.py` for user notification.
- **Testing:** Unit tests in `tests/unit/` using `unittest` or `pytest`.
- **Dependency Management:** `requirements.txt`.

## 3. Data Flow

1. User provides requirements text via CLI.
2. `main.py` passes text to `InputParser`.
3. `InputParser` returns cleaned text.
4. `main.py` passes cleaned text to `UseCaseGenerator`.
5. `UseCaseGenerator` interacts with LLM API, returns list of use case strings/objects.
6. `main.py` iterates through use cases, passing each to `SearchEngine`.
7. `SearchEngine` queries sources, fetches details, returns a list of top N findings for that use case.
8. `main.py` collects all findings and passes them (along with original use cases) to `ResultsFormatter`.
9. `ResultsFormatter` generates a Markdown string.
10. `main.py` prints the Markdown string to the console.
